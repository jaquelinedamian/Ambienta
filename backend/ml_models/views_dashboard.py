# backend/ml_models/views_dashboard.py
from django.shortcuts import render
from django.utils import timezone
from datetime import timedelta
import json
from .models import MLModel, MLPrediction, TrainingSession
from django.contrib.auth.decorators import login_required
from django.db.models import Count, Q, Avg, F, ExpressionWrapper, FloatField
from sensors.models import FanState, FanLog, Reading
from django.conf import settings
from functools import wraps
from django.http import HttpResponse
import logging
import traceback

logger = logging.getLogger(__name__)

def handle_dashboard_errors(view_func):
    @wraps(view_func)
    def wrapper(request, *args, **kwargs):
        try:
            return view_func(request, *args, **kwargs)
        except Exception as e:
            logger.error(f"Erro no dashboard ML: {str(e)}")
            logger.error(traceback.format_exc())
            
            # Contexto mínimo para o template
            error_context = {
                'error_message': 'Desculpe, ocorreu um erro ao carregar o dashboard.',
                'active_models': [],
                'recent_predictions': [],
                'predictions_24h': 0,
                'anomaly_predictions': [],
                'anomalies_today': 0,
                'total_predictions': 0,
                'recent_training': [],
                'fan_state': False,
                'fan_confidence': None,
                'energy_savings': 0,
                'fan_effectiveness': 0,
                'fan_optimization_history': []
            }
            
            return render(request, 'dashboard/ml_dashboard.html', error_context)
    return wrapper

@login_required
@handle_dashboard_errors
def ml_dashboard(request):
    """View para o dashboard de Machine Learning"""
    
    print("\n=== INÍCIO DO PROCESSAMENTO DA VIEW ===")
    print(f"DEBUG - URL acessada: {request.path}")

    try:
        # Buscar modelos ativos
        active_models = MLModel.objects.filter(is_active=True)
        if not active_models.exists():
            logger.warning("Nenhum modelo ML ativo encontrado")
    except Exception as e:
        logger.error(f"Erro ao buscar modelos ativos: {e}")
        active_models = MLModel.objects.none()
    
    try:
        # Buscar últimas predições com seus modelos relacionados
        recent_predictions = MLPrediction.objects.select_related('model').order_by('-created_at')[:10]
    except Exception as e:
        logger.error(f"Erro ao buscar predições recentes: {e}")
        recent_predictions = MLPrediction.objects.none()
    
    # Converter e formatar os dados de predição para um formato mais amigável
    for prediction in recent_predictions:
        # Converter de string para dict se necessário
        if isinstance(prediction.prediction, str):
            try:
                prediction.prediction = json.loads(prediction.prediction)
            except json.JSONDecodeError:
                continue
        
        # Garantir que prediction.prediction é um dicionário
        if not isinstance(prediction.prediction, dict):
            prediction.prediction = {}
        
        # Formatar dados específicos para cada tipo de modelo
        if prediction.model.model_type == 'temperature_prediction':
            # Garantir que temperatures é uma lista
            if 'temperatures' not in prediction.prediction:
                prediction.prediction = {
                    'temperatures': [prediction.prediction.get('predicted_temp', 0.0)]
                }
            elif isinstance(prediction.prediction['temperatures'], (int, float)):
                prediction.prediction['temperatures'] = [prediction.prediction['temperatures']]
        
        elif prediction.model.model_type == 'fan_optimization':
            # Garantir campos necessários para otimização do ventilador
            default_fan_data = {
                'should_turn_on': prediction.prediction.get('should_turn_on', False),
                'recommended_duration_minutes': prediction.prediction.get('recommended_duration_minutes', 0),
                'confidence': prediction.prediction.get('confidence', 0.0)
            }
            prediction.prediction.update(default_fan_data)
        
        elif prediction.model.model_type == 'anomaly_detection':
            # Garantir campos necessários para detecção de anomalias
            default_anomaly_data = {
                'is_anomaly': prediction.prediction.get('is_anomaly', False),
                'anomaly_score': prediction.prediction.get('anomaly_score', 0.0)
            }
            prediction.prediction.update(default_anomaly_data)
    
    # Predições nas últimas 24h por tipo de modelo
    last_24h = timezone.now() - timedelta(hours=24)
    recent_predictions_24h = MLPrediction.objects.filter(
        created_at__gte=last_24h
    ).select_related('model').order_by('-created_at')
    
    # Anomalias detectadas hoje
    today = timezone.now().date()
    anomaly_predictions = MLPrediction.objects.filter(
        model__model_type='anomaly_detection',
        created_at__date=today
    ).select_related('model').order_by('-created_at')

    # Separar anomalias confirmadas
    anomalies = anomaly_predictions.filter(prediction__is_anomaly=True)
    
    # Histórico de treinamento recente
    recent_training = TrainingSession.objects.all().order_by('-started_at')[:5]
    
    # Métricas gerais
    total_predictions = MLPrediction.objects.count()
    predictions_24h = recent_predictions_24h.count()

    # Dados de otimização do ventilador
    try:
        # Buscar estado do ventilador de forma segura
        fan_state = FanState.objects.last()
        fan_state = fan_state.state if fan_state else False
    except Exception as e:
        print(f"Erro ao buscar estado do ventilador: {e}")
        fan_state = False
    
    try:
        # Última predição do ventilador
        last_fan_prediction = MLPrediction.objects.filter(
            model__model_type='fan_optimization'
        ).order_by('-created_at').first()

        fan_confidence = None
        if last_fan_prediction and isinstance(last_fan_prediction.prediction, dict):
            fan_confidence = int(last_fan_prediction.prediction.get('confidence', 0) * 100)
    except Exception as e:
        print(f"Erro ao buscar predição do ventilador: {e}")
        fan_confidence = None

    try:
        # Calcular economia de energia
        last_month = timezone.now() - timedelta(days=30)
        fan_logs = FanLog.objects.filter(start_time__gte=last_month)
        
        # Tempo médio ligado antes da otimização vs depois
        optimization_model = MLModel.objects.filter(
            model_type='fan_optimization',
            is_active=True
        ).first()
        
        optimization_start = optimization_model.created_at if optimization_model else None
    except Exception as e:
        print(f"Erro ao calcular economia de energia: {e}")
        fan_logs = []
        optimization_start = None

    if optimization_start:
        before_optimization = fan_logs.filter(
            start_time__lt=optimization_start
        ).aggregate(
            avg_duration=Avg('duration')
        )['avg_duration'] or 0

        after_optimization = fan_logs.filter(
            start_time__gte=optimization_start
        ).aggregate(
            avg_duration=Avg('duration')
        )['avg_duration'] or 0

        if before_optimization > 0:
            energy_savings = ((before_optimization - after_optimization) / before_optimization) * 100
        else:
            energy_savings = 0
    else:
        energy_savings = 0

    # Calcular efetividade (redução média de temperatura)
    fan_effectiveness = 0
    
    # Buscar apenas os logs mais recentes que têm tanto start_time quanto end_time
    recent_fan_logs = FanLog.objects.filter(
        start_time__gte=timezone.now() - timedelta(days=7),
        start_time__isnull=False,
        end_time__isnull=False
    ).order_by('-start_time')[:10]  # Reduzido para 10 logs mais recentes
    
    if recent_fan_logs:
        # Preparar listas de IDs e timestamps para busca em lote
        log_times = [(log.id, log.start_time, log.end_time) for log in recent_fan_logs]
        
        temperature_reductions = []
        for log_id, start_time, end_time in log_times:
            try:
                # Buscar as temperaturas antes e depois em uma única query para cada log
                temps = Reading.objects.filter(
                    (Q(timestamp__lte=start_time) | Q(timestamp__gte=end_time))
                ).order_by('timestamp')[:2]  # Limita a 2 leituras

            except Exception as e:
                logger.error(f"Erro ao buscar leituras para log: {e}")
                continue

            # Se temos exatamente 2 leituras (antes e depois)
            if len(temps) == 2:
                temp_before, temp_after = temps
                reduction = temp_before.temperature - temp_after.temperature
                if reduction > 0:  # Só considerar quando houve redução
                    temperature_reductions.append(reduction)

        if temperature_reductions:
            fan_effectiveness = (sum(temperature_reductions) / len(temperature_reductions)) * 100

    # Histórico de otimizações
    fan_optimization_history = []
    # Usar os mesmos logs e temperaturas já carregados para o histórico
    log_count = len(log_times)
    logger.info(f"Total de logs recentes: {log_count}")
    
    for idx, (log_id, start_time, end_time) in enumerate(log_times, 1):
        try:
            logger.info(f"Processando log {idx}/{log_count} (ID: {log_id})")
            
            # Buscar as temperaturas em uma única query
            temps = Reading.objects.filter(
                (Q(timestamp__lte=start_time) | Q(timestamp__gte=end_time))
            ).order_by('timestamp')[:2]

            if len(temps) == 2:
                temp_before, temp_after = temps
                reduction = max(0, temp_before.temperature - temp_after.temperature)
                
                logger.debug(
                    f"Log {log_id}: Redução de temperatura: {reduction:.1f}°C "
                    f"(de {temp_before.temperature:.1f}°C para {temp_after.temperature:.1f}°C)"
                )

                # Criar entrada para o histórico
                entry = {
                    'timestamp': start_time,
                    'temperature': temp_before.temperature,
                    'duration': (end_time - start_time).total_seconds() / 60,
                    'temperature_reduction': round(reduction, 1),
                    'end_time': end_time
                }
                fan_optimization_history.append(entry)
            else:
                logger.warning(f"Log {log_id}: Temperaturas insuficientes para análise")
            
        except Exception as e:
            logger.error(f"Erro ao processar log {log_id}: {e}")
            continue
    anomalies_today = anomalies.count()
    
    print("\n=== INICIALIZANDO DADOS DO VENTILADOR ===")
    # Valores padrão para segurança
    default_fan_data = {
        'fan_state': False,
        'fan_confidence': None,
        'energy_savings': 0,
        'fan_effectiveness': 0,
        'fan_optimization_history': []
    }
    
    try:
        # Inicializar dados do ventilador com valores reais
        fan_data = {
            'fan_state': fan_state,
            'fan_confidence': fan_confidence,
            'energy_savings': round(float(energy_savings), 1) if energy_savings is not None else 0,
            'fan_effectiveness': round(float(fan_effectiveness), 1) if fan_effectiveness is not None else 0,
            'fan_optimization_history': fan_optimization_history if fan_optimization_history else []
        }
        
        # Validar dados antes de usar
        if not isinstance(fan_data['energy_savings'], (int, float)):
            logger.warning(f"Valor inválido para energy_savings: {fan_data['energy_savings']}")
            fan_data['energy_savings'] = 0
            
        if not isinstance(fan_data['fan_effectiveness'], (int, float)):
            logger.warning(f"Valor inválido para fan_effectiveness: {fan_data['fan_effectiveness']}")
            fan_data['fan_effectiveness'] = 0
            
    except Exception as e:
        logger.error(f"Erro ao processar dados do ventilador: {e}")
        fan_data = default_fan_data.copy()
    
    # Garantir que todos os campos necessários existem
    for key in default_fan_data:
        if key not in fan_data:
            fan_data[key] = default_fan_data[key]
    
    # Montar contexto completo
    context = {
        # Dados base
        'active_models': active_models or [],
        'recent_predictions': recent_predictions or [],
        'predictions_24h': predictions_24h or 0,
        'anomaly_predictions': anomaly_predictions or [],
        'anomalies_today': anomalies_today or 0,
        'total_predictions': total_predictions or 0,
        'recent_training': recent_training or [],
        
        # Dados do ventilador
        **fan_data
    }

    # Log detalhado do contexto final
    logger.info("=== RESUMO DO DASHBOARD ===")
    logger.info(f"Modelos ativos: {active_models.count() if active_models else 0}")
    logger.info(f"Predições recentes: {len(recent_predictions)}")
    logger.info(f"Predições 24h: {predictions_24h}")
    logger.info(f"Anomalias hoje: {anomalies_today}")
    logger.info(f"Estado do ventilador: {'LIGADO' if fan_state else 'DESLIGADO'}")
    logger.info(f"Confiança ML: {fan_confidence}%")
    logger.info(f"Economia de energia: {fan_data['energy_savings']:.1f}%")
    logger.info(f"Efetividade: {fan_data['fan_effectiveness']:.1f}%")
    logger.info(f"Histórico de otimizações: {len(fan_optimization_history)} registros")
    logger.info("==========================")
    
    return render(request, 'dashboard/ml_dashboard.html', context)